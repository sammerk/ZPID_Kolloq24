@article{ioannidis2005,
  title = {Why Most Published Research Findings Are False},
  author = {Ioannidis, John P A},
  year = {2005},
  journal = {PLoS Medicine},
  volume = {2},
  number = {8},
  doi = {10.1371/journal.pmed.0020124},
  file = {/Users/samuelmerk/Zotero/storage/76XIFWIQ/Ioannidis_2005_Why most published research findings are false.pdf}
}
@article{douglas2023,
  title = {Data Quality in Online Human-Subjects Research: {{Comparisons}} between {{MTurk}}, {{Prolific}}, {{CloudResearch}}, {{Qualtrics}}, and {{SONA}}},
  shorttitle = {Data Quality in Online Human-Subjects Research},
  author = {Douglas, Benjamin D. and Ewell, Patrick J. and Brauer, Markus},
  editor = {Hallam, Jeffrey S.},
  year = {2023},
  month = mar,
  journal = {PLOS ONE},
  volume = {18},
  number = {3},
  pages = {e0279720},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0279720},
  urldate = {2024-01-11},
  abstract = {With the proliferation of online data collection in human-subjects research, concerns have been raised over the presence of inattentive survey participants and non-human respondents (bots). We compared the quality of the data collected through five commonly used platforms. Data quality was indicated by the percentage of participants who meaningfully respond to the researcher's question (high quality) versus those who only contribute noise (low quality). We found that compared to MTurk, Qualtrics, or an undergraduate student sample (i.e., SONA), participants on Prolific and CloudResearch were more likely to pass various attention checks, provide meaningful answers, follow instructions, remember previously presented information, have a unique IP address and geolocation, and work slowly enough to be able to read all the items. We divided the samples into high- and low-quality respondents and computed the cost we paid per high-quality respondent. Prolific (\$1.90) and CloudResearch (\$2.00) were cheaper than MTurk (\$4.36) and Qualtrics (\$8.17). SONA cost \$0.00, yet took the longest to collect the data.},
  langid = {english},
  file = {/Users/samuelmerk/Zotero/storage/MBMM4IY2/Douglas et al. - 2023 - Data quality in online human-subjects research Co.pdf}
}


@article{franconeri2021,
  title = {The Science of Visual Data Communication: {{What}} Works},
  shorttitle = {The {{Science}} of {{Visual Data Communication}}},
  author = {Franconeri, Steven L. and Padilla, Lace M. and Shah, Priti and Zacks, Jeffrey M. and Hullman, Jessica},
  year = {2021},
  month = dec,
  journal = {Psychological Science in the Public Interest},
  volume = {22},
  number = {3},
  pages = {110--161},
  issn = {1529-1006, 1539-6053},
  doi = {10.1177/15291006211051956},
  urldate = {2021-12-24},
  abstract = {Effectively designed data visualizations allow viewers to use their powerful visual systems to understand patterns in data across science, education, health, and public policy. But ineffectively designed visualizations can cause confusion, misunderstanding, or even distrust---especially among viewers with low graphical literacy. We review research-backed guidelines for creating effective and intuitive visualizations oriented toward communicating data to students, coworkers, and the general public. We describe how the visual system can quickly extract broad statistics from a display, whereas poorly designed displays can lead to misperceptions and illusions. Extracting global statistics is fast, but comparing between subsets of values is slow. Effective graphics avoid taxing working memory, guide attention, and respect familiar conventions. Data visualizations can play a critical role in teaching and communication, provided that designers tailor those visualizations to their audience.},
  langid = {english},
  keywords = {JF},
  file = {/Users/samuelmerk/Zotero/storage/IQ32EQYY/Franconeri et al_2021_The science of visual data communication.pdf}
}

@article{merk2023,
  title = {Rich Data, Poor Information? {{Teachers}}' Perceptions of Mean Differences in Graphical Feedback from Statewide Tests},
  author = {Merk, Samuel and Gro{\ss} Ophoff, Jana and Kelava, Augustin},
  year = {2023},
  month = apr,
  journal = {Learning and Instruction},
  volume = {84},
  pages = {101717},
  issn = {0959-4752},
  doi = {10.1016/j.learninstruc.2022.101717},
  abstract = {Data-based decision making in schools aims to address students' needs and improve their performance by leveraging the information contained in data. However, to learn from data, teachers are required to transform them into actionable information. In two studies, we focused on how teachers can learn about the strengths and weaknesses of their class performance from statewide test data by investigating how sensitively, efficiently, and accurately they are able to judge the magnitude of mean differences. The results indicate that teachers can judge mean differences with very high accuracy ({$\tau~$}=~.85) but only consider moderate and large effects to be meaningful, indicating low sensitivity. By systematically varying different graph types, we also found that participants quickly increased their efficiency in terms of dwell time when repeatedly confronted with a specific graph type and were most sensitive to the use of stacked or clustered bar graphs.},
  keywords = {Data literacy,Data-based decision making,Graph comprehension,Standardized tests,Teacher education},
  file = {/Users/samuelmerk/Zotero/storage/G7ZR8KUQ/Merk et al_2023_Rich data, poor information.pdf}
}

@article{kruschke2018a,
  title = {Rejecting or {{Accepting Parameter Values}} in {{Bayesian Estimation}}},
  author = {Kruschke, John K.},
  year = {2018},
  month = jun,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {2},
  pages = {270--280},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245918771304},
  urldate = {2024-01-05},
  abstract = {This article explains a decision rule that uses Bayesian posterior distributions as the basis for accepting or rejecting null values of parameters. This decision rule focuses on the range of plausible values indicated by the highest density interval of the posterior distribution and the relation between this range and a region of practical equivalence (ROPE) around the null value. The article also discusses considerations for setting the limits of a ROPE and emphasizes that analogous considerations apply to setting the decision thresholds for p values and Bayes factors.},
  langid = {english},
  file = {/Users/samuelmerk/Zotero/storage/AQAZEPTU/Kruschke_2018_Rejecting or Accepting Parameter Values in Bayesian Estimation.pdf}
}

@article{burkner2017,
  title = {Brms: An R Package for Bayesian Multilevel Models Using Stan},
  author = {Bürkner, Paul-Christian},
  year = {2017},
  journal = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  issn = {1548-7660},
  doi = {https://doi.org/10.18637/jss.v080.i01},
  urldate = {2021-09-09},
  langid = {english},
}
@article{vehtari2021,
  title = {{Rank-normalization, folding, and localization: An improved R\^{} for assessing convergence of MCMC (with discussion)}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and Bürkner, Paul-Christian},
  year = {2021},
  month = Jun,
  journal = {Bayesian Analysis},
  volume = {16},
  number = {2},
  issn = {1936-0975},
  doi = {https://doi.org/10.1214/20-BA1221},
  urldate = {2024-03-27},
}@article{burkner2019,
  title = {Ordinal {{Regression Models}} in {{Psychology}}: {{A Tutorial}}},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {B{\"u}rkner, Paul-Christian and Vuorre, Matti},
  year = {2019},
  month = mar,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {1},
  pages = {77--101},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245918823199},
  urldate = {2023-02-17},
  abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  langid = {english},
  file = {/Users/samuelmerk/Zotero/storage/UB5J5VN6/Bürkner und Vuorre - 2019 - Ordinal Regression Models in Psychology A Tutoria.pdf}
}

@article{stosic2024,
  title = {Careless {{Responding}}: {{Why Many Findings Are Spurious}} or {{Spuriously Inflated}}},
  shorttitle = {Careless {{Responding}}},
  author = {Stosic, Morgan D. and Murphy, Brett A. and Duong, Fred and Fultz, Amber A. and Harvey, Summer E. and Bernieri, Frank},
  year = {2024},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {7},
  number = {1},
  pages = {25152459241231581},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/25152459241231581},
  urldate = {2024-06-18},
  abstract = {Contrary to long-standing conventional wisdom, failing to exclude data from carelessly responding participants on questionnaires or behavioral tasks will frequently result in false-positive or spuriously inflated findings. Despite prior publications demonstrating this disturbing statistical confound, it continues to be widely underappreciated by most psychologists, including highly experienced journal editors. In this article, we aim to comprehensively explain and demonstrate the severity and widespread prevalence of careless responding's (CR) inflationary effects in psychological research. We first describe when and why one can expect to observe the inflationary effect of unremoved CR data in a manner accessible to early graduate or advanced undergraduate students. To this end, we provide an online simulator tool and instructional videos for use in classrooms. We then illustrate realistic magnitudes of the severity of unremoved CR data by presenting novel reanalyses of data sets from three high-profile articles: We found that many of their published effects would have been meaningfully, sometimes dramatically, inflated if they had not rigorously screened out CR data. To demonstrate the frequency with which researchers fail to adequately screen for CR, we then conduct a systematic review of CR screening procedures in studies using paid online samples (e.g., MTurk) published across two prominent psychological-science journals. These findings suggest that most researchers either did not conduct any kind of CR screening or conducted only bare minimal screening. To help researchers avoid publishing spuriously inflated findings, we summarize best practices to help mitigate the threats of CR data.},
  langid = {english},
  file = {/Users/samuelmerk/Zotero/storage/2ML7ALIE/Stosic et al_2024_Careless Responding.pdf}
}

@misc{schmidt2024a,
  title = {Communicating Effect Sizes to Teachers. {{Exploring}} Different Visualizations and Their Enrichment Options},
  author = {Schmidt, Kirstin and Schneider, J{\"u}rgen and Bohrer, Kristina and Merk, Samuel},
  year = {2024}
}

@inproceedings{kim2019a,
  title = {Effectively Communicating Effect Sizes},
  author = {Kim, Yea-Seul},
  year = {2019},
  file = {/Users/samuelmerk/Zotero/storage/DMIKZ3T5/Kim_2019_Effectively communicating effect sizes.pdf}
}


@article{hullman2015,
  title = {Hypothetical Outcome Plots Outperform Error Bars and Violin Plots for Inferences about Reliability of Variable Ordering},
  author = {Hullman, Jessica and Resnick, Paul and Adar, Eytan},
  editor = {Papaleo, Elena},
  year = {2015},
  month = nov,
  journal = {PLOS ONE},
  volume = {10},
  number = {11},
  pages = {e0142444},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0142444},
  urldate = {2022-08-28},
  langid = {english},
  file = {/Users/samuelmerk/Zotero/storage/AUV93VYS/Hullman et al_2015_Hypothetical outcome plots outperform error bars and violin plots for.pdf}
}

@article{michal2024,
  title = {A {{Practical Significance Bias}} in {{Laypeople}}'s {{Evaluation}} of {{Scientific Findings}}},
  author = {Michal, Audrey L. and Shah, Priti},
  year = {2024},
  month = mar,
  journal = {Psychological Science},
  pages = {09567976241231506},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1177/09567976241231506},
  urldate = {2024-04-08},
  abstract = {People often rely on scientific findings to help them make decisions---however, failing to report effect magnitudes might lead to a potential bias in assuming findings are practically significant. Across two online studies (Prolific; N = 800), we measured U.S. adults' endorsements of expensive interventions described in media reports that led to effects that were small, large, or of unreported magnitude between groups. Participants who viewed interventions with unreported effect magnitudes were more likely to endorse interventions compared with those who viewed interventions with small effects and were just as likely to endorse interventions as those who viewed interventions with large effects, suggesting a practical significance bias. When effect magnitudes were reported, participants on average adjusted their evaluations accordingly. However, some individuals, such as those with low numeracy skills, were more likely than others to act on small effects, even when explicitly prompted to first consider the meaningfulness of the effect.},
  langid = {english},
  file = {/Users/samuelmerk/Zotero/storage/Y98LWYX6/Michal_Shah_2024_A Practical Significance Bias in Laypeople’s Evaluation of Scientific Findings.pdf}
}

@article{kale2020,
  title = {Visual Reasoning Strategies for Effect Size Judgments and Decisions},
  author = {Kale, Alex and Kay, Matthew and Hullman, Jessica},
  year = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2007.14516},
  urldate = {2022-08-18},
  abstract = {Uncertainty visualizations often emphasize point estimates to support magnitude estimates or decisions through visual comparison. However, when design choices emphasize means, users may overlook uncertainty information and misinterpret visual distance as a proxy for effect size. We present findings from a mixed design experiment on Mechanical Turk which tests eight uncertainty visualization designs: 95\% containment intervals, hypothetical outcome plots, densities, and quantile dotplots, each with and without means added. We find that adding means to uncertainty visualizations has small biasing effects on both magnitude estimation and decision-making, consistent with discounting uncertainty. We also see that visualization designs that support the least biased effect size estimation do not support the best decision-making, suggesting that a chart user's sense of effect size may not necessarily be identical when they use the same information for different tasks. In a qualitative analysis of users' strategy descriptions, we find that many users switch strategies and do not employ an optimal strategy when one exists. Uncertainty visualizations which are optimally designed in theory may not be the most effective in practice because of the ways that users satisfice with heuristics, suggesting opportunities to better understand visualization effectiveness by modeling sets of potential strategies.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Human-Computer Interaction (cs.HC)},
  file = {/Users/samuelmerk/Zotero/storage/G7SWT895/Kale et al_2020_Visual reasoning strategies for effect size judgments and decisions.pdf}
}

@article{nickerson1998,
  title = {Confirmation Bias: {{A}} Ubiquitous Phenomenon in Many Guises},
  author = {Nickerson, Raymond S.},
  year = {1998},
  journal = {Review of General Psychology},
  volume = {2},
  number = {2},
  pages = {175--220},
  doi = {10.1037/1089-2680.2.2.175},
  file = {/Users/samuelmerk/Zotero/storage/HM6MXQYV/Nickerson_1998_Confirmation bias.pdf}
}


@article{sackett1996,
  title = {Evidence Based Medicine: What It Is and What It Isn't.},
  shorttitle = {Evidence Based Medicine},
  author = {Sackett, D. L. and Rosenberg, W. M. and Gray, J. A. and Haynes, R. B. and Richardson, W. S.},
  year = {1996},
  month = jan,
  journal = {BMJ : British Medical Journal},
  volume = {312},
  number = {7023},
  pages = {71--72},
  issn = {0959-8138},
  urldate = {2023-01-30},
  pmcid = {PMC2349778},
  pmid = {8555924},
  keywords = {important,to-read},
  file = {/Users/kirstinschmidt/GDrive_Mac/zotero-library/AUTH/Sackett et al/sackett_et_al_1996_evidence_based_medicine_-_what_it_is_and_what_it_isn't.pdf}
}


@article{bauer2023,
  title = {{(Wie) kann die Nutzung bildungswissenschaftlicher Evidenz Lehren und Lernen verbessern? Thesen und Fragen zur Diskussion um evidenzorientiertes Denken und Handeln von Lehrkr{\"a}ften}},
  shorttitle = {{(Wie) kann die Nutzung bildungswissenschaftlicher Evidenz Lehren und Lernen verbessern?}},
  author = {Bauer, Johannes and Kollar, Ingo},
  year = {2023},
  month = mar,
  journal = {Unterrichtswissenschaft},
  issn = {2520-873X},
  doi = {10.1007/s42010-023-00166-1},
  urldate = {2023-03-06},
  abstract = {Vor dem Hintergrund von Debatten um evidenzbasierte Praxis im Bildungswesen greift der vorliegende Beitrag aktuelle Forschungsstr{\"a}nge auf, die sich mit evidenzorientiertem Denken und Handeln von Lehrkr{\"a}ften (EDHL) befassen. Sie adressieren aus unterschiedlichen Perspektiven Voraussetzungen, Prozesse und Ergebnisse der Rezeption und Nutzung (bildungs-)wissenschaftlichen Wissens durch angehende und aktive Lehrkr{\"a}fte sowie Interventionen zur F{\"o}rderung hierf{\"u}r relevanter Kompetenzen und motivational-affektiver Dispositionen. Im Beitrag diskutieren wir erstens, dass sich in diesem Feld --~trotz der Heterogenit{\"a}t von Fragestellungen und theoretischen Zug{\"a}ngen~-- ein Verst{\"a}ndnis von EDHL etabliert hat, das in zentralen Punkten konvergiert. Zweitens werfen wir Thesen und Fragen auf, die es k{\"u}nftig konzeptuell und empirisch zu adressieren hat. Abschlie{\ss}end gehen wir auf {\"u}bergeordnete kontextuelle Barrieren ein, die aus unserer Sicht {\"u}berwunden werden m{\"u}ssen, um eine st{\"a}rkere Evidenzorientierung in der Bildungspraxis zu erreichen.},
  langid = {ngerman},
  keywords = {Evidence-based practice,Evidence-oriented reasoning and acting,Evidenzbasierte Praxis,Evidenzorientiertes Denken und Handeln,important,Lehramtsstudierende,Lehrkrafte,Preservice teachers,Professionalism,Professionalitat,read,Teachers},
  file = {/Users/kirstinschmidt/GDrive_Mac/zotero-library/AUTH/Bauer_Kollar/bauer_kollar_2023_(wie)_kann_die_nutzung_bildungswissenschaftlicher_evidenz_lehren_und_lernen.pdf}
}


@article{APA2006,
  title = {Evidence-Based Practice in Psychology},
  author = {{APA Presidential Task Force on Evidence-Based Practice}},
  year = {2006},
  journal = {The American Psychologist},
  volume = {61},
  number = {4},
  pages = {271--285},
  issn = {0003-066X},
  doi = {10.1037/0003-066X.61.4.271},
  abstract = {The evidence-based practice movement has become an important feature of health care systems and health care policy. Within this context, the APA 2005 Presidential Task Force on Evidence-Based Practice defines and discusses evidence-based practice in psychology (EBPP). In an integration of science and practice, the Task Force's report describes psychology's fundamental commitment to sophisticated EBPP and takes into account the full range of evidence psychologists and policymakers must consider. Research, clinical expertise, and patient characteristics are all supported as relevant to good outcomes. EBPP promotes effective psychological practice and enhances public health by applying empirically supported principles of psychological assessment, case formulation, therapeutic relationship, and intervention. The report provides a rationale for and expanded discussion of the EBPP policy statement that was developed by the Task Force and adopted as association policy by the APA Council of Representatives in August 2005.},
  langid = {english},
  pmid = {16719673},
  keywords = {Evidence-Based Medicine,Humans,Mental Disorders,Practice Patterns Physicians',Psychology}
}

